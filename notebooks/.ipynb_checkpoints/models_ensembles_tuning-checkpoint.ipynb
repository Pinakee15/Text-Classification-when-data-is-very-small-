{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In this section, we'll use the features we created in the previous section, along with IDF-weighted embeddings and try them on different models. \n",
    "\n",
    "As mentioned earlier, when dealing with small datasets, low-complexity models like Logistic Regression, SVMs and Naive Bayes will generalize the best. We'll try these models along with non-parameteric models like KNN and non-linear models like Random Forest, XGBoost etc. \n",
    "\n",
    "We'll also try bootstrap-aggregating or bagging with the best-performing classifier along with stacking using VotingClassifer. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts with number....\n",
      "Clickbait Phrases....\n",
      "Clickbait re....\n",
      "Num dots....\n",
      "Text Features....\n",
      "Punctuation....\n",
      "Word ratios....\n",
      "Sentiment Scores....\n",
      "Readability Scores....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1f983853cd4c4d9c8ae54571d7e7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d332e04c154470addc73538472c536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glove.....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89e4bcff37a48b58b4fe0595dbc18bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fc2e9717a34b0e9457f419952ac01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "from featurization import *\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train = pd.read_csv('../datasets/train.csv')\n",
    "test = pd.read_csv('../datasets/test.csv')\n",
    "train_features, test_features, feature_names = featurize(train, test, 'tfidf_glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_train = np.where(train.label.values == 'clickbait', 1, 0)\n",
    "y_test = np.where(test.label.values == 'clickbait', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "GridSearchCV HelperFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "\n",
    "def adjusted_f1(y_true, y_prob):\n",
    "    f1 = print_model_metrics(y_true, y_prob, verbose = 0, return_metrics = True)[0]\n",
    "    return f1\n",
    "\n",
    "score = make_scorer(adjusted_f1, greater_is_better = True, needs_proba = True)\n",
    "\n",
    "\n",
    "\n",
    "# Since we want to use a predefined Test/Val set, we'll use PredefinedSplit and pass it as the CV parameter\n",
    "# We need to merge both the datasets and label 0 for test and -1 for the train set\n",
    "\n",
    "X = sparse.vstack((train_features, test_features))\n",
    "test_fold = [-1 for _ in range(train_features.shape[0])] + [0 for _ in range(test_features.shape[0])]\n",
    "y = np.concatenate([y_train, y_test])\n",
    "ps = PredefinedSplit(test_fold)\n",
    "\n",
    "def run_grid_search(model, params, x_train, y_train):\n",
    "    grid = GridSearchCV(model, params, cv = ps, n_jobs = -1, scoring = score, verbose = 0, refit = False)\n",
    "    grid.fit(x_train, y_train)\n",
    "    return (grid.best_params_, grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run log reg n times and average the metrics\n",
    "def fit_n_times(model, x_train, y_train, x_test, y_test, n_iters = 10):\n",
    "    metrics = np.zeros(5)\n",
    "    for _ in range(n_iters):\n",
    "        model.fit(x_train, y_train)\n",
    "        y_test_prob = model.predict_proba(x_test)[:,1]\n",
    "        metrics += print_model_metrics(y_test, y_test_prob, verbose = False, return_metrics = True)\n",
    "    metrics /=10\n",
    "    print('F1: {:.3f} | Pr: {:.3f} | Re: {:.3f} | AUC: {:.3f} | Accuracy: {:.3f} \\n'.format(*metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Log Reg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters : {'alpha': 0.1, 'l1_ratio': 0.15, 'penalty': 'elasticnet'}\n",
      "F1: 0.966 | Pr: 0.959 | Re: 0.974 | AUC: 0.994 | Accuracy: 0.966 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr = SGDClassifier(loss = 'log')\n",
    "lr_params = {'alpha' : [10**(-x) for x in range(7)],\n",
    "             'penalty' : ['l1', 'l2', 'elasticnet'],\n",
    "             'l1_ratio' : [0.15, 0.25, 0.5, 0.75]}\n",
    "\n",
    "best_params, best_f1 = run_grid_search(lr, lr_params, X, y)\n",
    "\n",
    "print('Best Parameters : {}'.format(best_params))\n",
    "\n",
    "lr = SGDClassifier(loss = 'log', \n",
    "                   alpha = best_params['alpha'], \n",
    "                   penalty = best_params['penalty'], \n",
    "                   l1_ratio = best_params['l1_ratio'])\n",
    "fit_n_times(lr, train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters : {'C': 10, 'degree': 2, 'kernel': 'poly'}\n",
      "Best F1 : 0.9683981828955164\n",
      "F1: 0.968 | Pr: 0.956 | Re: 0.981 | AUC: 0.994 | Accuracy: 0.968 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(probability = True)\n",
    "svm_params = {'C' : [10**(x) for x in range(-1,4)],\n",
    "             'kernel' : ['poly', 'rbf', 'linear'],\n",
    "             'degree' : [2, 3]}\n",
    "\n",
    "best_params, best_f1 = run_grid_search(svm, svm_params, X, y)\n",
    "\n",
    "print('Best Parameters : {}'.format(best_params))\n",
    "print('Best F1 : {}'.format(best_f1))\n",
    "\n",
    "svm = SVC(C = best_params['C'], kernel = best_params['kernel'], degree = best_params['degree'], probability = True)\n",
    "fit_n_times(svm, train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": true
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters : {'alpha': 10000}\n",
      "Best F1 : 0.9634676145339652\n",
      "F1: 0.963 | Pr: 0.951 | Re: 0.976 | AUC: 0.993 | Accuracy: 0.963 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB(class_prior = [0.5, 0.5])\n",
    "nb_params = {'alpha' : [10**(x) for x in range(6)]}\n",
    "\n",
    "\n",
    "best_params, best_f1 = run_grid_search(nb, nb_params, X, y)\n",
    "\n",
    "print('Best Parameters : {}'.format(best_params))\n",
    "print('Best F1 : {}'.format(best_f1))\n",
    "\n",
    "nb = MultinomialNB(alpha = best_params['alpha'], class_prior = [0.5, 0.5])\n",
    "\n",
    "fit_n_times(nb, train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": true
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters : {'n_neighbors': 7, 'weights': 'distance'}\n",
      "F1: 0.962 | Pr: 0.955 | Re: 0.970 | AUC: 0.992 | Accuracy: 0.962 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs = -1)\n",
    "\n",
    "knn_params = { 'n_neighbors' : [3, 5, 7, 9, 15, 31], \n",
    "               'weights' : ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "best_params, best_f1 = run_grid_search(knn, knn_params, X, y)\n",
    "print('Best Parameters : {}'.format(best_params))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = best_params['n_neighbors'], weights = best_params['weights'], n_jobs = -1)\n",
    "\n",
    "fit_n_times(knn, train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters : {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 250}\n",
      "F1: 0.957 | Pr: 0.950 | Re: 0.964 | AUC: 0.991 | Accuracy: 0.956 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "rf_params = { 'n_estimators' : [10, 100, 250, 500, 1000], \n",
    "               'max_depth' : [None, 3, 7, 15],\n",
    "               'min_samples_split' : [2, 5, 15]\n",
    "}\n",
    "\n",
    "best_params, best_f1 = run_grid_search(rf, rf_params, X, y)\n",
    "\n",
    "print('Best Parameters : {}'.format(best_params))\n",
    "rf = RandomForestClassifier(n_estimators = best_params['n_estimators'],\n",
    "                            min_samples_split = best_params['min_samples_split'],\n",
    "                            max_depth = best_params['max_depth'], \n",
    "                            n_jobs = -1)\n",
    "fit_n_times(rf, train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": true
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters : {'learning_rate': 0.3, 'max_depth': 1, 'n_estimators': 100, 'reg_alpha': 0}\n",
      "F1: 0.955 | Pr: 0.947 | Re: 0.964 | AUC: 0.990 | Accuracy: 0.955 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_jobs = -1)\n",
    "\n",
    "xgb_params = { 'n_estimators' : [10, 100, 200, 500], \n",
    "               'max_depth' : [1, 2, 3, 7],\n",
    "               'learning_rate' : [0.1, 0.2, 0.01, 0.3],\n",
    "               'reg_alpha' : [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "best_params, best_f1 = run_grid_search(xgb, xgb_params, X, y)\n",
    "\n",
    "print('Best Parameters : {}'.format(best_params))\n",
    "xgb = XGBClassifier(n_estimators = best_params['n_estimators'],\n",
    "                            learning_rate = best_params['learning_rate'],\n",
    "                            max_depth = best_params['max_depth'], \n",
    "                            reg_alpha = best_params['reg_alpha'], \n",
    "                            n_jobs = -1)\n",
    "fit_n_times(rf, train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## DL Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 40\n",
    "\n",
    "simple_nn = Sequential()\n",
    "simple_nn.add(Dense(150, activation='relu', input_shape=(119,)))\n",
    "simple_nn.add(Dropout(0.2))\n",
    "simple_nn.add(Dense(100, activation='relu'))\n",
    "simple_nn.add(Dropout(0.2))\n",
    "simple_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "simple_nn.summary()\n",
    "\n",
    "simple_nn.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('./saved_models', monitor = 'val_accuracy', verbose = 1, save_best_only=True)\n",
    "history = simple_nn.fit(train_features.todense(), y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [checkpoint],\n",
    "                    validation_data=(test_features.todense(), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "simple_nn = load_model('./saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.961 | Pr: 0.952 | Re: 0.970 | AUC: 0.992 | Accuracy: 0.960 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = simple_nn.predict(test_features.todense())\n",
    "print_model_metrics(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Since SVM worked so well, we can try a bagging classifier by using SVM as a base estimator. This should improve the variance of the base model and reduce overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.968 | Pr: 0.961 | Re: 0.975 | AUC: 0.995 | Accuracy: 0.968 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "svm = SVC(C = 10, kernel = 'poly', degree = 2, probability = True, verbose = 0)\n",
    "\n",
    "svm_bag = BaggingClassifier(svm, n_estimators = 200, max_features = 0.9, max_samples = 1.0, bootstrap_features = False, bootstrap = True, n_jobs = 1, verbose = 0)\n",
    "\n",
    "svm_bag.fit(train_features, y_train)\n",
    "y_test_prob = svm_bag.predict_proba(test_features)[:,1]\n",
    "print_model_metrics(y_test, y_test_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Stacking Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Finally, one last thing we can try is the Stacking Classifier = basically a weighted average of the predictions of different models. Since we are using the fast ai tabular learner we wont be able to use Sklearn's `VotingClassifier` instead we'll just run a simple loop that gets the predictions of each model and runs a weighted average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR\n",
      "Training SVM\n",
      "Training NB\n",
      "Training KNN\n",
      "Training RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/.local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGB\n",
      "F1: 0.970 | Pr: 0.967 | Re: 0.972 | AUC: 0.995 | Accuracy: 0.970 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define all models \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr = SGDClassifier(loss = 'log', alpha = 0.1, penalty = 'elasticnet')\n",
    "svm = SVC(C = 10, kernel = 'poly', degree = 2, probability = True)\n",
    "nb = MultinomialNB(alpha = 10000, class_prior = [0.5, 0.5])\n",
    "knn = KNeighborsClassifier(n_neighbors = 7, weights = 'distance', n_jobs = -1)\n",
    "rf = RandomForestClassifier(n_estimators = 250, min_samples_split = 5, max_depth = 15,  n_jobs = -1)\n",
    "xgb = XGBClassifier(n_estimators = 100, learning_rate = 0.3, max_depth = 1, n_jobs = -1)\n",
    "\n",
    "model_dict = dict(zip(['LR', 'SVM', 'NB', 'KNN', 'RF', 'XGB'], [lr, svm, nb, knn, rf, xgb]))\n",
    "\n",
    "for model_name, model in model_dict.items():\n",
    "    print('Training {}'.format(model_name))\n",
    "    model.fit(train_features, y_train)\n",
    "\n",
    "model_weights = {   'LR' : 0.9,\n",
    "                    'SVM' : 0.9,\n",
    "                    'NB' : 0.8,\n",
    "                    'KNN' : 0.75,\n",
    "                    'RF' : 0.75,\n",
    "                    'XGB' : 0.6,\n",
    "                    'simple_nn' : 0.7\n",
    "}\n",
    "\n",
    "y_pred_prob = 0\n",
    "\n",
    "for model_name, model in model_dict.items():\n",
    "    y_pred_prob += (model.predict_proba(test_features)[:,1] * model_weights[model_name])\n",
    "\n",
    "y_pred_prob += (simple_nn.predict(test_features.todense()).ravel() * model_weights['simple_nn'])\n",
    "y_pred_prob /= sum(model_weights.values())\n",
    "\n",
    "print_model_metrics(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def run_voting_clf(model_weights):\n",
    "    #result_list, model_weights = data\n",
    "    \n",
    "    y_pred_prob = 0\n",
    "\n",
    "    for model_name, model in model_dict.items():\n",
    "        y_pred_prob += (model.predict_proba(test_features)[:,1] * model_weights[model_name])\n",
    "\n",
    "    #y_pred_prob += (simple_nn.get_preds(ds_type = DatasetType.Valid)[0].numpy()[:,0] * model_weights['simple_nn'])\n",
    "    y_pred_prob += (simple_nn.predict(test_features.todense()).ravel() * model_weights['simple_nn'])\n",
    "    y_pred_prob /= sum(model_weights.values())\n",
    "    f1 = print_model_metrics(y_test, y_pred_prob, return_metrics = True, verbose = 0)[0]\n",
    "    return {'loss' : -f1, 'status' : STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [08:45<00:00,  1.05s/it, best loss: -0.9708506841165973]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "trials = Trials()\n",
    "model_weights = fmin(run_voting_clf,\n",
    "    space= {\n",
    "        'LR' : hp.uniform('LR', 0, 1),\n",
    "        'SVM' : hp.uniform('SVM', 0, 1),\n",
    "        'NB' : hp.uniform('NB', 0, 1),\n",
    "        'KNN' : hp.uniform('KNN', 0, 1),\n",
    "        'RF' : hp.uniform('RF', 0, 1),\n",
    "        'XGB' : hp.uniform('XGB', 0, 1),\n",
    "        'simple_nn' : hp.uniform('simple_nn', 0, 1),\n",
    "\n",
    "\n",
    "    },\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=500,\n",
    "    trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model_weights = {'KNN': 0.7866810233035141,\n",
    " 'LR': 0.8036572275670447,\n",
    " 'NB': 0.9102009774357307,\n",
    " 'RF': 0.1559824350958057,\n",
    " 'SVM': 0.9355079606348642,\n",
    " 'XGB': 0.33469066125332436,\n",
    " 'simple_nn': 0.000545264707939086}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.971 | Pr: 0.963 | Re: 0.980 | AUC: 0.995 | Accuracy: 0.971 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = 0\n",
    "for model_name, model in model_dict.items():\n",
    "    y_pred_prob += (model.predict_proba(test_features)[:,1] * model_weights[model_name])\n",
    "\n",
    "y_pred_prob += (simple_nn.predict(test_features.todense()).ravel() * model_weights['simple_nn'])\n",
    "y_pred_prob /= sum(model_weights.values())\n",
    "print_model_metrics(y_test, y_pred_prob, confusion = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(y_test, y_pred_prob, pos_label = 1)\n",
    "    \n",
    "#Find the threshold value that gives the best F1 Score\n",
    "best_f1_index =np.argmax([calc_f1(p_r) for p_r in zip(precision, recall)])\n",
    "best_threshold, best_precision, best_recall = threshold[best_f1_index], precision[best_f1_index], recall[best_f1_index]\n",
    "\n",
    "# Calulcate predictions based on the threshold value\n",
    "y_test_pred = np.where(y_test_prob > best_threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_idx = y_test != y_test_pred\n",
    "high_confidence_indices = np.argsort(y_test_prob[misclassified_idx])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Those Who Lost Savings Find Little Comfort', 'not-clickbait'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[misclassified_idx].values[279]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title : Those Who Lost Savings Find Little Comfort\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.8737945792317662\n",
      "----------\n",
      "Title : Smartphone From Dell? Just Maybe\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.8881080427675058\n",
      "----------\n",
      "Title : Male models win The Amazing Race\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.8909699961891452\n",
      "----------\n",
      "Title : Ainge Has Heart Attack After Celtics Say Garnett May Miss Playoffs\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.8916277123562639\n",
      "----------\n",
      "Title : If Vick Is Sincere, Give Him a Chance to Prove It\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.894014300180017\n",
      "----------\n",
      "Title : Cellphone Abilities That Go Untapped\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.8969317223056715\n",
      "----------\n",
      "Title : A Peaking Tiger Woods\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9113495803235656\n",
      "----------\n",
      "Title : A Little Rugby With Your Cross-Dressing?\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9120835562001224\n",
      "----------\n",
      "Title : Woods Returns as He Left: A Winner\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.930506343172195\n",
      "----------\n",
      "Title : Darwinism Must Die So That Evolution May Live\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9334297085656929\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for idx in high_confidence_indices:\n",
    "    print('Title : {}'.format(test[misclassified_idx].title.values[idx]))\n",
    "    print('Label : {}'.format(test[misclassified_idx].label.values[idx]))\n",
    "    print('Predicted Probability : {}'.format(y_test_prob[misclassified_idx][idx]))\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Insurgents Are Said to Capture Somali Town',\n",
       "       'Abducted teen in Florida found',\n",
       "       'As Iraq Stabilizes, China Eyes Its Oil Fields',\n",
       "       'Paramilitary group calls for end to rioting in Northern Ireland',\n",
       "       'Finding Your Way Through a Maze of Smartphones',\n",
       "       'Thousands demand climate change action',\n",
       "       'Paternity Makes Punch Line of Paraguay President',\n",
       "       'Comcast and NFL Network Continue to Haggle',\n",
       "       'Constant Fear and Mob Rule in South Africa Slum',\n",
       "       'Sebastian Vettel wins 2010 Japanese Grand Prix'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.label.values == 'not-clickbait'].sample(10).title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
